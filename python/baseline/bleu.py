"""Multi-bleu in python matching Moses http://www.statmt.org/moses/?n=Moses.SupportTools#ntoc5

Reference files and prediction files must be sentence aligned. To use multiple
references use multiple reference files (all sentence aligned)

All text should already be tokenized (calling `.split()` on the line produces correct tokens)
"""

import six
from six.moves import reduce, map, zip, range

import sys
import argparse
from operator import or_
from itertools import chain
from collections import Counter
import numpy as np


def n_grams(tokens, n):
    """Create a list for n grams for each value up to and including n.

    :param tokens: `List[str]` The sequence to create n_grams on.
    :param n: `int` or `tuple[int]` If int the largest n_gram to create else
        the n_grams to create.

    :returns: `iterable` An iterable of the n_grams.
    """
    n = range(n + 1) if isinstance(n, int) else n
    return chain(*(zip(*[tokens[i:] for i in range(n_)]) for n_ in n))


def count_n_grams(tokens, n):
    """Count the n_grams in a sequence.

    :param tokens: `List[str]` The sequence to create n_grams on.
    :param n: `int` or `tuple[int]` If int the largest n_gram to create else
        the n_grams to create.

    :returns: `Counter[n_gram]` The counts of each n_gram.
    """
    return Counter(n_grams(tokens, n))


def find_closest(pred_len, golds):
    """Find the gold sentence that has the most similar length to pred.

    Note:
        When there are multiple sentence with the same different in length
        to the pred length the shortest one is selected.

    :param pred_len: `int` The length of the predicted sentence.
    :param golds: `List[List[str]]` The gold sentences.

    :returns: `int` The length of the selected gold sentence.
    """
    best_diff = six.MAXSIZE; best_len = six.MAXSIZE;
    for gold in golds:
        gold_len = len(gold)
        diff = abs(pred_len - gold_len)
        if diff < best_diff:
            best_diff = diff
            best_len = gold_len
        elif diff == best_diff:
            best_len = gold_len if gold_len < best_len else best_len
    return best_len


def corpora_lengths(preds, golds):
    """Calculate the length of the two corpora.

    The length of the pred corpus is just the sum of lengths, the length
    of the gold corpus is the sum of the lengths of a single gold selected
    from a set of golds. This single gold is selected to be the length that
    is closest to the pred lengths (in the event of ties select the shorter
    gold sentence).

    :param preds: `List[List[str]]` A list of sentences generated by the model.
        This is [B, T] where B is the number of examples in the dataset and T
        is the number of words in that prediction.
    :param golds: `List[List[List[str]]]` A list of gold sentences. This is
        [B, R, T] where B is the number of examples in the dataset, R is the
        number of gold sentences we have for a particular example, and T is the
        number of words in that gold sentence.

    :returns: `(int, int)` The length of the predicted corpus and the length of
        the gold corpus.
    """
    pred_len = 0; gold_len = 0
    for pred, gold in zip(preds, golds):
        pred_len += len(pred)
        gold_len += find_closest(len(pred), gold)
    return pred_len, gold_len


def max_gold_n_gram_counts(golds, n):
    """Find the maximum n gram count for the gold sequences.

    :param golds: `List[List[str]]` The gold sentences.
    :param n: `int` The max size of n-grams we are using.

    :returns: `Counter[str]` The maximum count for any n-gram that appears
        in a gold sentence.
    """
    # or_ is the union of counters so result is max count for each n gram
    # that appears in the any of the gold sentences.
    return reduce(or_, map(lambda g: count_n_grams(g, n), golds))


def count_matches(pred_counts, gold_counts, matches):
    """Aggregate the number of matches for each n gram length.

    :param pred_counts: `Counter[str]` The counts for n grams found in the
        predicted sentence.
    :param gold_counts: `Counter[str]` The max counts for n grams found in
        the gold sentences.
    :param matches: `np.ndarray` The number of matches found so far grouped
        by n-gram size.

    :returns: `np.ndarry` The number of matches so far grouped by n-gram size.
    """
    # & is the intersection of counters, selecting the min of each n gram
    # that appears in both if the counters.
    overlap = pred_counts & gold_counts
    for n_gram, count in overlap.items():
        matches[len(n_gram) - 1] += count
    return matches


def count_possible(pred, total):
    """Count the total number of possible matches.

    We recalculate the total possible rather than use the counts calculated
    before because the counts aren't binned by length.

    :param pred: `List[str]` The predicted sentence.
    :param total: `np.ndarry` The current total number of possible matches
        grouped by size.

    :returns: `np.ndarry` The new number of possible n-gram matches of far
        grouped by size.
    """
    for n in range(len(total)):
        # Possible number of n_grams for a sequence is the length of the sequence
        # minus the length of the n_gram plus 1. In this case n_ is already
        # one less than length of n_gram so just subtract that.
        total_grams = len(pred) - n
        if total_grams > 0:
            total[n] += total_grams
    return total


def geometric_mean(precision):
    """Calculate the geometric mean of the precision.

    Geometric mean is the nth root of the product of n numbers. This
    can be expressed as the e^(arithmetic mean of the logs). The geometric
    mean only applies to positive number and any 0 is the values makes the
    answer trivially zero to checkout for that first to avoid log(0).

    :param precision: `np.ndarry` The precision for each n-gram size.

    :returns: `float` The geometric_mean of the values.
    """
    if np.min(precision) <= 0:
        return 0.0
    return np.exp(np.mean(np.log(precision))).item()


def brevity_penalty(pred_len, gold_len):
    """Calculate the brevity penalty.

    Note:
        multi-bleu.pl crashes when the hypothesis corpus is completely empty.
        We don't want training to crash so we set the penalty to `0` because as
        the reference corpus grows arbitrary large ((gold / pred) approach
        infinity and the limit of e^(1 - x) as x -> infinity is 0.

        We also return a np.nan for the length ratio for a visual cue that the
        lengths were weird in the cli.

    :param pred_len: `int` The length of the model prediction corpus
    :param gold_len: `int` The length of the gold corpus

    :returns: (`float`, `float`): The brevity penalty and the ratio of predicted
        length to gold length.
    """
    if pred_len == 0: return 0, np.nan
    ratio = pred_len / float(gold_len)
    # If ratio is <= 1.0 then pred_len <= gold_len so penalty applies.
    # Penalty is defined as e^(1 - (gold / pred)). (1 / (p / g)) = (g / p)
    bp = np.exp(1 - (1. / ratio)).item() if ratio <= 1.0 else 1.0
    return bp, ratio


def bleu(preds, golds, n=4):
    """Calculate BLEU score

    This implementation is designed to match the output of `multi-bleu,pl` from
    http://www.statmt.org/moses/?n=Moses.SupportTools#ntoc5

    :param preds: `List[List[str]]` A list of sentences generated by the model.
        This is [B, T] where B is the number of examples in the dataset and T
        is the number of words in that prediction.
    :param golds: `List[List[List[str]]]` A list of gold sentences. This is
        [B, R, T] where B is the number of examples in the dataset, R is the
        number of gold sentences we have for a particular example, and T is the
        number of words in that gold sentence.
    :param n: `int` The max size n-gram to use.

    :returns:
        6-tuple (
            `float` The Bleu score,
            `np.array` The precision for each n_gram,
            `float` The brevity penalty,
            `int` The length of the predictions,
            `int` The length of the references,
        )
    """
    matches = np.zeros(n)
    total = np.zeros(n)
    pred_len, gold_len = corpora_lengths(preds, golds)
    for pred, gold in zip(preds, golds):
        max_gold_counts = max_gold_n_gram_counts(gold, n)
        pred_counts = count_n_grams(pred, n)
        matches = count_matches(pred_counts, max_gold_counts, matches)
        total = count_possible(pred, total)

    precision = np.array([matches[i] / float(total[i]) if total[i] > 0 else 0.0 for i in range(n)])
    geo_mean = geometric_mean(precision)
    bp, len_ratio = brevity_penalty(pred_len, gold_len)
    b = geo_mean * bp * 100
    return (b, precision * 100, bp, len_ratio, pred_len, gold_len)


# Slightly strange file readers that read from pre opened files to facilitate
# reading the predictions from stdin. Won't be used elsewhere.
def _read_references(reference_files, lc):
    """Read from multiple reference files.

    :param reference_file: `List[str]` A list of reference files to read from.
    :param lc: `bool` should the input be lowercased

    :return: `List[List[List[str]]]` The reference corpus is the form `[B, R, T]`
        where B is the number of sentences in the corpus, R is the number of
        references for that sentence and T is the number of words in that reference
    """
    references = []
    for ref in reference_files:
        with open(ref) as f:
            references.append(_read_lines(f, lc))
    return list(zip(*references))


def _read_lines(f, lc):
    """Read from a file that is open."""
    if lc:
        return list(map(lambda x: list(map(lambda y: y.lower(), x.split())), f))
    return list(map(lambda x: x.split(), f))


def main():
    """Use as a cli tools like multibleu.pl"""
    usage = "%(prog)s [-lc] [-n] reference < hypothesis\nReads the references from reference or reference0, reference1, ...\n"
    parser = argparse.ArgumentParser(description="Calculate Bleu score.", usage=usage)
    parser.add_argument('-lc', help='lowercase the input', action='store_true')
    parser.add_argument('-n', type=int, default=4, help='The number of ngrams to use.')
    parser.add_argument('reference', nargs='+')
    args = parser.parse_args()

    golds = _read_references(args.reference, args.lc)
    preds = _read_lines(sys.stdin, args.lc)

    b, precision, bp, len_ratio, pred_len, gold_len = bleu(preds, golds, args.n)
    precision_str = "/".join(["{:.1f}"] * len(precision)).format(*precision)

    print("BLEU = {bleu:.2f}, {per} (BP={bp:.3f}, ratio={ratio:.3f}, hyp_len={hyp}, ref_len={ref})".format(
        bleu=b, per=precision_str, bp=bp, ratio=len_ratio, hyp=pred_len, ref=gold_len
    ))


if __name__ == "__main__":
    main()
