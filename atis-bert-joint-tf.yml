task: tagger
backend: tensorflow
conll_output: atis-bert.conll
unif: 0.1
dataset: atis-joint-intent
basedir: atis-bert
preproc:
  mxlen: -1
  mxwlen: -1

features:
 - name: word
   vectorizer:
     label: bert-base-uncased-dict1d
   embeddings:
     type: tlm-words-embed
     word_embed_type: learned-positional-w-bias
     label: bert-base-uncased-npz
     reduction: sum-layer-norm
     layer_norms_after: true
     finetune: true
     mlm: true
loader:
  reader_type: joint
  named_fields: {"0": "text", "-1": "y"}
  label_vectorizer:
    label: y
    type: wordpiece-label-dict1d

model:
  model_type: pass-joint
  constrain_decode: 0
  crf: 0
  dropout: 0.65
  alpha: 0.5

train:
  trainer_type: joint-trainer
  batchsz: 4
  epochs: 2
  optim: adam
  eta: 1.0e-5
  patience: 15
  early_stopping_metric: tagging_f1
  clip: 5.0
  span_type: iobes
